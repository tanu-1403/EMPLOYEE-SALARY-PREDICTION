{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2c06287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_year</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_currency</th>\n",
       "      <th>salary_in_usd</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>remote_ratio</th>\n",
       "      <th>company_location</th>\n",
       "      <th>company_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>Research Scientist</td>\n",
       "      <td>208000</td>\n",
       "      <td>USD</td>\n",
       "      <td>208000</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>Research Scientist</td>\n",
       "      <td>147000</td>\n",
       "      <td>USD</td>\n",
       "      <td>147000</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Research Scientist</td>\n",
       "      <td>173000</td>\n",
       "      <td>USD</td>\n",
       "      <td>173000</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Research Scientist</td>\n",
       "      <td>117000</td>\n",
       "      <td>USD</td>\n",
       "      <td>117000</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>AI Engineer</td>\n",
       "      <td>100000</td>\n",
       "      <td>USD</td>\n",
       "      <td>100000</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93592</th>\n",
       "      <td>2020</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>412000</td>\n",
       "      <td>USD</td>\n",
       "      <td>412000</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93593</th>\n",
       "      <td>2021</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>151000</td>\n",
       "      <td>USD</td>\n",
       "      <td>151000</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93594</th>\n",
       "      <td>2020</td>\n",
       "      <td>EN</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>105000</td>\n",
       "      <td>USD</td>\n",
       "      <td>105000</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93595</th>\n",
       "      <td>2020</td>\n",
       "      <td>EN</td>\n",
       "      <td>CT</td>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>100000</td>\n",
       "      <td>USD</td>\n",
       "      <td>100000</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93596</th>\n",
       "      <td>2021</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>7000000</td>\n",
       "      <td>INR</td>\n",
       "      <td>94665</td>\n",
       "      <td>IN</td>\n",
       "      <td>50</td>\n",
       "      <td>IN</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93597 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       work_year experience_level employment_type                 job_title  \\\n",
       "0           2025               MI              FT        Research Scientist   \n",
       "1           2025               MI              FT        Research Scientist   \n",
       "2           2025               SE              FT        Research Scientist   \n",
       "3           2025               SE              FT        Research Scientist   \n",
       "4           2025               MI              FT               AI Engineer   \n",
       "...          ...              ...             ...                       ...   \n",
       "93592       2020               SE              FT            Data Scientist   \n",
       "93593       2021               MI              FT  Principal Data Scientist   \n",
       "93594       2020               EN              FT            Data Scientist   \n",
       "93595       2020               EN              CT     Business Data Analyst   \n",
       "93596       2021               SE              FT            Data Scientist   \n",
       "\n",
       "        salary salary_currency  salary_in_usd employee_residence  \\\n",
       "0       208000             USD         208000                 US   \n",
       "1       147000             USD         147000                 US   \n",
       "2       173000             USD         173000                 US   \n",
       "3       117000             USD         117000                 US   \n",
       "4       100000             USD         100000                 US   \n",
       "...        ...             ...            ...                ...   \n",
       "93592   412000             USD         412000                 US   \n",
       "93593   151000             USD         151000                 US   \n",
       "93594   105000             USD         105000                 US   \n",
       "93595   100000             USD         100000                 US   \n",
       "93596  7000000             INR          94665                 IN   \n",
       "\n",
       "       remote_ratio company_location company_size  \n",
       "0                 0               US            M  \n",
       "1                 0               US            M  \n",
       "2                 0               US            M  \n",
       "3                 0               US            M  \n",
       "4               100               US            M  \n",
       "...             ...              ...          ...  \n",
       "93592           100               US            L  \n",
       "93593           100               US            L  \n",
       "93594           100               US            S  \n",
       "93595           100               US            L  \n",
       "93596            50               IN            L  \n",
       "\n",
       "[93597 rows x 11 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(r\"C:\\Users\\DELL\\Downloads\\archive\\DataScience_salaries_2025.csv\")\n",
    "df  # Display the first few rows of the DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2739ba65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column: work_year\n",
      "[2025 2024 2022 2023 2020 2021]\n",
      "\n",
      "Column: experience_level\n",
      "['MI' 'SE' 'EN' 'EX']\n",
      "\n",
      "Column: employment_type\n",
      "['FT' 'PT' 'CT' 'FL']\n",
      "\n",
      "Column: job_title\n",
      "['Research Scientist' 'AI Engineer' 'Manager'\n",
      " 'Business Intelligence Developer' 'Software Engineer' 'Data Scientist'\n",
      " 'Research Engineer' 'Data Specialist' 'AI Architect' 'Business Analyst'\n",
      " 'Machine Learning Engineer' 'Data Analyst' 'Data Architect'\n",
      " 'Data Engineer' 'Analyst' 'Engineer' 'Data Analytics Manager'\n",
      " 'Business Development Representative' 'Analytics Engineer'\n",
      " 'Research Associate' 'Product Specialist' 'Systems Engineer' 'Associate'\n",
      " 'Data Governance' 'Software Development Engineer' 'Data Governance Lead'\n",
      " 'Software Developer' 'Statistician' 'Architect' 'Data Product Manager'\n",
      " 'Quantitative Researcher' 'Product Manager' 'Applied Scientist'\n",
      " 'Cloud Developer' 'Engineering Manager' 'Consultant' 'Product Designer'\n",
      " 'Data Operations' 'Statistical Programmer' 'Data Governance Analyst'\n",
      " 'Solution Architect' 'Data Modeler' 'Full Stack Developer'\n",
      " 'Data Management Lead' 'Business Intelligence Analyst'\n",
      " 'Postdoctoral Researcher' 'DevOps Engineer' 'Solutions Architect'\n",
      " 'Developer' 'Cloud Engineer' 'MLOps Engineer' 'Solutions Engineer'\n",
      " 'Data Lead' 'Data Manager' 'Data Management Specialist'\n",
      " 'Site Reliability Engineer' 'Data Integration Engineer'\n",
      " 'Director of Machine Learning' 'Data Reporting Analyst'\n",
      " 'Research Assistant' 'Application Developer' 'BI Engineer'\n",
      " 'Data Analytics Lead' 'Data Governance Specialist' 'Insight Analyst'\n",
      " 'Platform Engineer' 'Business Intelligence Engineer' 'Executive'\n",
      " 'Machine Learning Scientist' 'Head of Data' 'Computer Vision Engineer'\n",
      " 'BI Analyst' 'Postdoctoral Fellow' 'Python Developer' 'Backend Engineer'\n",
      " 'Full Stack Engineer' 'Data Management Analyst' 'AI Developer'\n",
      " 'Data Developer' 'Quantitative Analyst' 'Data Integrity Analyst'\n",
      " 'Product Owner' 'Product Analyst' 'Data Integrator'\n",
      " 'Data Governance Manager' 'Machine Learning Researcher' 'Analytics Lead'\n",
      " 'Member of Technical Staff' 'System Engineer'\n",
      " 'Enterprise Account Executive' 'Encounter Data Management Professional'\n",
      " 'Data Visualization Analyst' 'Data Management Consultant'\n",
      " 'Research Analyst' 'Technical Lead' 'QA Engineer' 'Lead Data Analysis'\n",
      " 'Data Management Associate' 'Head of AI' 'Data Infrastructure Engineer'\n",
      " 'Principal Researcher' 'Computational Scientist' 'BI Developer'\n",
      " 'Data Visualization Specialist' 'Data Quality Analyst'\n",
      " 'Data Quality Lead' 'Data Operations Engineer' 'Software Architect'\n",
      " 'Data Platform Engineer' 'AI Scientist' 'Data Product Owner'\n",
      " 'Data Visualization Expert' 'Data Integrity Specialist' 'Power BI Expert'\n",
      " 'Machine Learning Architect' 'Data and Reporting Professional'\n",
      " 'Decision Scientist' 'Bioinformatics Scientist' 'Lead Engineer'\n",
      " 'Data and Reporting Analyst' 'Developer Advocate' 'Data Strategist'\n",
      " 'Power BI' 'Account Executive' 'Data Operations Lead'\n",
      " 'Data Visualization Engineer' 'Data Operations Analyst' 'AI Researcher'\n",
      " 'AI Data Scientist' 'Robotics Engineer' 'Stage' 'Copywriter'\n",
      " 'Data Integration Specialist' 'Customer Success Manager'\n",
      " 'Computational Biologist' 'Actuarial Analyst' 'Data Reporter'\n",
      " 'Database Administrator' 'Quantitative Developer' 'Bioinformatician'\n",
      " 'Prompt Engineer' 'Analytics Specialist' 'AI Governance Lead'\n",
      " 'DataOps Engineer' 'Tableau Developer' 'Business Intelligence'\n",
      " 'Data Quality Specialist' 'Cloud Database Engineer' 'AI Data Engineer'\n",
      " 'ETL Developer' 'Technology Integrator' 'Algorithm Developer'\n",
      " 'AI Specialist' 'Business Intelligence Specialist' 'Java Developer'\n",
      " 'Power BI Developer' 'AI Product Owner' 'Principal Software Architect'\n",
      " 'Data Operations Specialist' 'Master Data Management'\n",
      " 'Data Analytics Specialist' 'Security Researcher' 'AI Research Scientist'\n",
      " 'Principal Statistical Programmer' 'Data Team Lead' 'Big Data Developer'\n",
      " 'Tech Lead' 'Scala Spark Developer' 'Sales Development Representative'\n",
      " 'Staff Data Scientist' 'Cloud Database Administrator'\n",
      " 'AI Machine Learning Engineer' 'Power BI Specialist' 'GenAI Architect'\n",
      " 'Lead Analyst' 'Head of Machine Learning' 'Data Analytics Consultant'\n",
      " 'Data Visualization Developer' 'Machine Learning Developer'\n",
      " 'Data Strategy Lead' 'Data Scientist Associate'\n",
      " 'Business Intelligence Manager' 'Risk Analyst'\n",
      " 'Marketing Science Partner' 'Data Reporting Specialist'\n",
      " 'Clinical Data Operator' 'AI Lead' 'Machine Learning Specialist'\n",
      " 'Research Data Manager' 'Technical Specialist'\n",
      " 'Applied Research Scientist' 'Lead Data Management'\n",
      " 'Data Analytics Developer' 'Machine Learning Lead' 'Technical Writer'\n",
      " 'Data Quality Engineer' 'Data Integration Analyst'\n",
      " 'Safety Data Management Specialist' 'Business Intelligence Lead'\n",
      " 'Data Operations Manager' 'Big Data Analyst' 'Data Scientist Manager'\n",
      " 'Pricing Analyst' 'Lead Data Engineer' 'AI Engineering Manager'\n",
      " 'Backend Developer' 'Data Management Coordinator' 'Analytics Analyst'\n",
      " 'Controls Engineer' 'Machine Learning Tech Lead'\n",
      " 'Business Development Manager' 'Business Insights Manager'\n",
      " 'Power BI Administrator' 'Data Integration Developer'\n",
      " 'Platform Data Engineer' 'Bear Robotics'\n",
      " 'Principal Application Delivery Consultant' 'Chatbot Developer'\n",
      " 'Artificial Intelligence Engineer' 'Data Governance Architect'\n",
      " 'Power BI Consultant' 'Backend Software Engineer' 'AI Product Manager'\n",
      " 'Data Operations Associate' 'ML Infrastructure Engineer'\n",
      " 'Fullstack Engineer' 'Machine Learning Quality Engineer'\n",
      " 'Security Engineer' 'Databricks Engineer' 'Infrastructure Engineer'\n",
      " 'Solution Engineer' 'Big Data Engineer'\n",
      " 'Machine Learning Performance Engineer' 'Data Analytics Associate'\n",
      " 'Power BI Architect' 'Machine Learning Platform Engineer'\n",
      " 'AI Solution Architect' 'Data Scientist Lead' 'Machine Vision Engineer'\n",
      " 'Data Governance Engineer' 'Machine Learning Model Engineer'\n",
      " 'Marketing Analyst' 'Data Management Manager'\n",
      " 'Marketing Analytics Manager' 'Applied AI ML Lead'\n",
      " 'Data Strategy Manager' 'Machine Learning Manager' 'Data Product Analyst'\n",
      " 'Data Quality Manager' 'Elasticsearch Administrator'\n",
      " 'Machine Learning Infrastructure Engineer' 'People Data Analyst'\n",
      " 'Frontend Engineer' 'NLP Engineer' 'SAS Developer'\n",
      " 'Data Analytics Team Lead' 'Machine Learning Modeler'\n",
      " 'Data Integration Coordinator' 'AI Programmer' 'Admin & Data Analyst'\n",
      " 'Head of Business Intelligence' 'ETL Engineer' 'AI Research Engineer'\n",
      " 'Business Intelligence Consultant' 'Robotics Software Engineer'\n",
      " 'AI Software Engineer' 'Lead AI Engineer'\n",
      " 'AI Software Development Engineer' 'Master Data Specialist'\n",
      " 'Consultant Data Engineer' 'Manager Data Management'\n",
      " 'Director of Business Intelligence' 'Lead Data Scientist'\n",
      " 'CRM Data Analyst' 'BI Data Analyst' 'Applied Data Scientist'\n",
      " 'Data DevOps Engineer' 'Quantitative Research Analyst'\n",
      " 'Lead Machine Learning Engineer' 'Machine Learning Research Engineer'\n",
      " 'Data Analyst Lead' 'Data Pipeline Engineer' 'Lead Data Analyst'\n",
      " 'Business Data Analyst' 'Marketing Data Scientist'\n",
      " 'Deep Learning Engineer' 'Financial Data Analyst' 'Azure Data Engineer'\n",
      " 'Principal Data Scientist' 'Staff Data Analyst'\n",
      " 'Machine Learning Software Engineer' 'Applied Machine Learning Scientist'\n",
      " 'Principal Machine Learning Engineer' 'Principal Data Engineer'\n",
      " 'Staff Machine Learning Engineer' 'Business Intelligence Data Analyst'\n",
      " 'Finance Data Analyst' 'Software Data Engineer' 'Compliance Data Analyst'\n",
      " 'Cloud Data Engineer' 'Analytics Engineering Manager'\n",
      " 'AWS Data Architect' 'Product Data Analyst'\n",
      " 'Autonomous Vehicle Technician' 'Sales Data Analyst'\n",
      " 'Applied Machine Learning Engineer' 'BI Data Engineer'\n",
      " 'Deep Learning Researcher' 'Big Data Architect'\n",
      " 'Computer Vision Software Engineer' 'Marketing Data Engineer'\n",
      " 'Data Science Tech Lead' 'Marketing Data Analyst'\n",
      " 'Principal Data Architect' 'Data Analytics Engineer'\n",
      " 'Cloud Data Architect' 'Principal Data Analyst']\n",
      "\n",
      "Column: salary\n",
      "[208000 147000 173000 ... 138350 423000 412000]\n",
      "\n",
      "Column: salary_currency\n",
      "['USD' 'EUR' 'GBP' 'TWD' 'BRL' 'CAD' 'HUF' 'PLN' 'JPY' 'PHP' 'CHF' 'INR'\n",
      " 'NOK' 'SGD' 'AUD' 'DKK' 'CZK' 'MXN' 'ILS' 'TRY' 'ZAR' 'SEK' 'NZD' 'HKD'\n",
      " 'THB' 'CLP']\n",
      "\n",
      "Column: salary_in_usd\n",
      "[208000 147000 173000 ...  28369 412000  94665]\n",
      "\n",
      "Column: employee_residence\n",
      "['US' 'LT' 'CA' 'FR' 'SK' 'GB' 'IT' 'RS' 'UA' 'PR' 'TW' 'BR' 'CY' 'NL'\n",
      " 'AT' 'DE' 'SE' 'AU' 'IN' 'IE' 'LV' 'ES' 'HU' 'PL' 'JP' 'PH' 'CH' 'BE'\n",
      " 'PE' 'AR' 'NZ' 'PT' 'FI' 'NO' 'SV' 'EC' 'CL' 'DO' 'MX' 'CO' 'SG' 'MT'\n",
      " 'DK' 'ID' 'MY' 'XK' 'CR' 'ZM' 'AM' 'LU' 'RW' 'IL' 'CZ' 'KR' 'ZA' 'EG'\n",
      " 'LB' 'GR' 'NG' 'BG' 'HR' 'KE' 'TR' 'PK' 'HN' 'RO' 'VE' 'BM' 'VN' 'GE'\n",
      " 'AE' 'SA' 'OM' 'BA' 'EE' 'UG' 'SI' 'MU' 'TH' 'QA' 'RU' 'TN' 'GH' 'AD'\n",
      " 'MD' 'UZ' 'HK' 'CF' 'KW' 'IR' 'AS' 'CN' 'BO' 'DZ' 'IQ' 'JE']\n",
      "\n",
      "Column: remote_ratio\n",
      "[  0 100  50]\n",
      "\n",
      "Column: company_location\n",
      "['US' 'LT' 'CA' 'FR' 'SK' 'GB' 'IT' 'RS' 'UA' 'PR' 'TW' 'BR' 'CY' 'NL'\n",
      " 'AT' 'DE' 'SE' 'AU' 'IN' 'IE' 'LV' 'ES' 'HU' 'PL' 'JP' 'PH' 'CH' 'BE'\n",
      " 'PE' 'AR' 'NZ' 'PT' 'FI' 'NO' 'SV' 'EC' 'CL' 'DO' 'MX' 'CO' 'MT' 'DK'\n",
      " 'ID' 'MY' 'XK' 'CR' 'ZM' 'AM' 'SG' 'LU' 'CD' 'IL' 'CZ' 'KR' 'ZA' 'EG'\n",
      " 'LB' 'GR' 'NG' 'BG' 'HR' 'KE' 'TR' 'PK' 'HN' 'RO' 'VE' 'DZ' 'AS' 'AE'\n",
      " 'SA' 'OM' 'BA' 'EE' 'VN' 'GI' 'SI' 'MU' 'RU' 'QA' 'GH' 'AD' 'HK' 'CF'\n",
      " 'TH' 'IR' 'BS' 'IQ' 'CN' 'MD']\n",
      "\n",
      "Column: company_size\n",
      "['M' 'L' 'S']\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(f\"\\nColumn: {col}\")\n",
    "    print(df[col].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a020183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            job_title      job_category\n",
      "0  Research Scientist  Quant / Research\n",
      "1  Research Scientist  Quant / Research\n",
      "2  Research Scientist  Quant / Research\n",
      "3  Research Scientist  Quant / Research\n",
      "4         AI Engineer        Core AI/ML\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Quant / Research', 'Core AI/ML', 'Other', 'BI / Visualization',\n",
       "       'Software / DevOps', 'Core Data Science', 'Architecture',\n",
       "       'Analyst / BI', 'Data Engineering', 'Data Governance / Quality',\n",
       "       'Statistical', 'Product / Strategy', 'Niche ML'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# JOB TITLE IN CATEGORIES\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Sample: Replace with your actual DataFrame\n",
    "# df = pd.read_csv(\"your_data.csv\")\n",
    "\n",
    "def categorize_job_title(title):\n",
    "    title = str(title).lower()  # Lowercase for easier matching\n",
    "\n",
    "    # Core AI/ML Roles\n",
    "    core_ai_ml_keywords = [\n",
    "        'ai engineer', 'machine learning engineer', 'ai researcher', 'ai scientist',\n",
    "        'applied scientist', 'machine learning scientist', 'applied research scientist',\n",
    "        'ai software engineer', 'machine learning lead', 'ai programmer', 'ai developer',\n",
    "        'ai specialist', 'machine learning developer', 'ai data scientist', 'machine learning tech lead',\n",
    "        'ai research engineer', 'applied ai ml lead', 'ai product manager', 'lead ai engineer',\n",
    "        'lead machine learning engineer', 'staff machine learning engineer', 'principal machine learning engineer',\n",
    "        'machine learning infrastructure engineer', 'machine learning model engineer', \n",
    "        'machine learning platform engineer', 'machine learning performance engineer', \n",
    "        'applied machine learning engineer', 'machine learning software engineer', \n",
    "        'applied machine learning scientist', 'machine learning modeler', 'ai governance lead',\n",
    "        'ai software development engineer', 'ai solution architect', 'ai engineering manager',\n",
    "        'director of machine learning', 'head of machine learning'\n",
    "    ]\n",
    "\n",
    "    # Niche ML Roles\n",
    "    niche_ml_keywords = ['deep learning', 'computer vision', 'nlp', 'prompt engineer']\n",
    "\n",
    "    # Core Data Science\n",
    "    data_science_keywords = ['data scientist']\n",
    "\n",
    "    # Data Analysts / Business Analysts\n",
    "    analyst_keywords = ['analyst', 'analytics', 'business analyst', 'marketing analyst', 'product analyst']\n",
    "\n",
    "    # Quantitative / Research Analysts\n",
    "    research_keywords = ['quantitative', 'research scientist', 'research analyst', 'researcher', 'bioinformatician']\n",
    "\n",
    "    # Data Engineering\n",
    "    data_engineer_keywords = ['data engineer', 'dataops', 'pipeline engineer', 'etl', 'integration engineer', 'databricks']\n",
    "\n",
    "    # Architecture\n",
    "    architect_keywords = ['architect']\n",
    "\n",
    "    # BI & Visualization\n",
    "    bi_keywords = ['business intelligence', 'bi', 'power bi', 'visualization']\n",
    "\n",
    "    # Data Governance / Quality\n",
    "    governance_keywords = ['governance', 'data quality', 'compliance', 'data integrity', 'master data']\n",
    "\n",
    "    # Software & DevOps\n",
    "    software_keywords = ['software engineer', 'developer', 'devops', 'qa', 'cloud engineer']\n",
    "\n",
    "    # Product / Strategy\n",
    "    product_keywords = ['product manager', 'head', 'director', 'strategy', 'lead']\n",
    "\n",
    "    # Statistical\n",
    "    statistical_keywords = ['statistician', 'statistical programmer', 'sas developer']\n",
    "\n",
    "    # Match categories\n",
    "    if any(keyword in title for keyword in core_ai_ml_keywords):\n",
    "        return 'Core AI/ML'\n",
    "    elif any(keyword in title for keyword in niche_ml_keywords):\n",
    "        return 'Niche ML'\n",
    "    elif any(keyword in title for keyword in data_science_keywords):\n",
    "        return 'Core Data Science'\n",
    "    elif any(keyword in title for keyword in analyst_keywords):\n",
    "        return 'Analyst / BI'\n",
    "    elif any(keyword in title for keyword in research_keywords):\n",
    "        return 'Quant / Research'\n",
    "    elif any(keyword in title for keyword in data_engineer_keywords):\n",
    "        return 'Data Engineering'\n",
    "    elif any(keyword in title for keyword in architect_keywords):\n",
    "        return 'Architecture'\n",
    "    elif any(keyword in title for keyword in bi_keywords):\n",
    "        return 'BI / Visualization'\n",
    "    elif any(keyword in title for keyword in governance_keywords):\n",
    "        return 'Data Governance / Quality'\n",
    "    elif any(keyword in title for keyword in software_keywords):\n",
    "        return 'Software / DevOps'\n",
    "    elif any(keyword in title for keyword in product_keywords):\n",
    "        return 'Product / Strategy'\n",
    "    elif any(keyword in title for keyword in statistical_keywords):\n",
    "        return 'Statistical'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "# Apply to your DataFrame\n",
    "df['job_category'] = df['job_title'].apply(categorize_job_title)\n",
    "\n",
    "# View result\n",
    "print(df[['job_title', 'job_category']].head())\n",
    "\n",
    "df['job_category'].unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "009d0a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            job_title      job_category  \\\n",
      "0  Research Scientist  Quant / Research   \n",
      "1  Research Scientist  Quant / Research   \n",
      "2  Research Scientist  Quant / Research   \n",
      "3  Research Scientist  Quant / Research   \n",
      "4         AI Engineer        Core AI/ML   \n",
      "\n",
      "                                     skills_required  \n",
      "0  Python, R, MATLAB, Stata, SQL, Statistics, Eco...  \n",
      "1  Python, R, MATLAB, Stata, SQL, Statistics, Eco...  \n",
      "2  Python, R, MATLAB, Stata, SQL, Statistics, Eco...  \n",
      "3  Python, R, MATLAB, Stata, SQL, Statistics, Eco...  \n",
      "4  Python, TensorFlow, PyTorch, Scikit-learn, MLf...  \n"
     ]
    }
   ],
   "source": [
    "#SKILL SET MAPPING\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Example: Your existing DataFrame\n",
    "# df = pd.read_csv(\"your_data.csv\")\n",
    "# Ensure df['job_category'] exists before proceeding\n",
    "\n",
    "# Define the skill mapping\n",
    "role_skillsets = {\n",
    "    'Quant / Research': [\n",
    "        'Python', 'R', 'MATLAB', 'Stata', 'SQL', 'Statistics', 'Econometrics',\n",
    "        'Quantitative Analysis', 'Machine Learning', 'Time Series Analysis', 'Pandas',\n",
    "        'NumPy', 'Academic Research', 'LaTeX', 'Jupyter Notebooks'\n",
    "    ],\n",
    "    'Core AI/ML': [\n",
    "        'Python', 'TensorFlow', 'PyTorch', 'Scikit-learn', 'MLflow', 'Deep Learning',\n",
    "        'Machine Learning', 'Computer Vision', 'NLP', 'Data Engineering', 'Data Cleaning',\n",
    "        'Model Deployment', 'MLOps', 'Docker', 'Kubernetes', 'Git'\n",
    "    ],\n",
    "    'Niche ML': [\n",
    "        'Deep Learning', 'PyTorch', 'TensorFlow', 'Keras', 'Computer Vision', 'OpenCV',\n",
    "        'Transformers', 'Hugging Face', 'NLP', 'Prompt Engineering', 'GANs',\n",
    "        'Reinforcement Learning'\n",
    "    ],\n",
    "    'Core Data Science': [\n",
    "        'Python', 'R', 'SQL', 'Pandas', 'Scikit-learn', 'Data Analysis',\n",
    "        'Machine Learning', 'Statistics', 'EDA', 'Dashboards', 'Tableau',\n",
    "        'Power BI', 'Jupyter', 'Data Storytelling'\n",
    "    ],\n",
    "    'Analyst / BI': [\n",
    "        'SQL', 'Excel', 'Power BI', 'Tableau', 'Looker', 'Data Cleaning',\n",
    "        'Data Visualization', 'Business Acumen', 'A/B Testing', 'Dashboards',\n",
    "        'Reporting', 'KPI Analysis'\n",
    "    ],\n",
    "    'BI / Visualization': [\n",
    "        'Tableau', 'Power BI', 'Looker', 'Data Studio', 'SQL', 'Excel',\n",
    "        'DAX', 'Data Modeling', 'Dashboard Design', 'Storytelling with Data',\n",
    "        'ETL Basics'\n",
    "    ],\n",
    "    'Data Engineering': [\n",
    "        'Python', 'SQL', 'Apache Spark', 'Kafka', 'Airflow', 'ETL Pipelines',\n",
    "        'Data Warehousing', 'Snowflake', 'BigQuery', 'Databricks',\n",
    "        'AWS/GCP/Azure', 'Docker', 'CI/CD', 'DBT'\n",
    "    ],\n",
    "    'Architecture': [\n",
    "        'Cloud Platforms (AWS/GCP/Azure)', 'Data Architecture', 'Solution Architecture',\n",
    "        'Infrastructure as Code', 'Kubernetes', 'Docker', 'CI/CD', 'Microservices',\n",
    "        'System Design', 'Security', 'Networking'\n",
    "    ],\n",
    "    'Software / DevOps': [\n",
    "        'Python', 'Java', 'C++', 'Git', 'CI/CD', 'Docker', 'Kubernetes',\n",
    "        'Jenkins', 'Terraform', 'Cloud Platforms', 'Monitoring Tools (Prometheus/Grafana)',\n",
    "        'Agile/Scrum', 'Unit Testing'\n",
    "    ],\n",
    "    'Data Governance / Quality': [\n",
    "        'SQL', 'Data Quality Tools', 'Data Catalogs', 'Metadata Management',\n",
    "        'Data Lineage', 'GDPR', 'Data Stewardship', 'Master Data Management (MDM)',\n",
    "        'Collibra', 'Informatica', 'Data Auditing'\n",
    "    ],\n",
    "    'Statistical': [\n",
    "        'R', 'SAS', 'Python', 'SPSS', 'Statistical Modeling', 'Hypothesis Testing',\n",
    "        'Regression Analysis', 'Survival Analysis', 'Clinical Trials', 'Pharma Data Standards',\n",
    "        'ANOVA', 'Experimental Design'\n",
    "    ],\n",
    "    'Product / Strategy': [\n",
    "        'Product Management', 'Jira', 'Aha!', 'SQL', 'Data Analysis',\n",
    "        'Market Research', 'User Research', 'BI Tools', 'A/B Testing',\n",
    "        'OKRs/KPIs', 'Leadership', 'Agile', 'Stakeholder Communication'\n",
    "    ],\n",
    "    'Other': [\n",
    "        'General Programming', 'Soft Skills', 'Domain Knowledge',\n",
    "        'Project Coordination', 'Documentation', 'Cross-Functional Skills',\n",
    "        'Adaptability', 'Problem Solving'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Map the job category to the skill set\n",
    "df['skills_required'] = df['job_category'].map(role_skillsets)\n",
    "\n",
    "# Optional: Convert skill lists to comma-separated strings for readability\n",
    "df['skills_required'] = df['skills_required'].apply(lambda x: ', '.join(x) if isinstance(x, list) else 'N/A')\n",
    "\n",
    "# Preview\n",
    "print(df[['job_title', 'job_category', 'skills_required']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db3bfe10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   work_year experience_level employment_type           job_title  salary  \\\n",
      "0       2025        Mid Level       Full-time  Research Scientist  208000   \n",
      "1       2025        Mid Level       Full-time  Research Scientist  147000   \n",
      "2       2025     Senior Level       Full-time  Research Scientist  173000   \n",
      "3       2025     Senior Level       Full-time  Research Scientist  117000   \n",
      "4       2025        Mid Level       Full-time         AI Engineer  100000   \n",
      "\n",
      "  salary_currency  salary_in_usd employee_residence work_location  \\\n",
      "0             USD         208000                 US       On-site   \n",
      "1             USD         147000                 US       On-site   \n",
      "2             USD         173000                 US       On-site   \n",
      "3             USD         117000                 US       On-site   \n",
      "4             USD         100000                 US        Remote   \n",
      "\n",
      "  company_location company_size      job_category  \\\n",
      "0               US       Medium  Quant / Research   \n",
      "1               US       Medium  Quant / Research   \n",
      "2               US       Medium  Quant / Research   \n",
      "3               US       Medium  Quant / Research   \n",
      "4               US       Medium        Core AI/ML   \n",
      "\n",
      "                                     skills_required  \n",
      "0  Python, R, MATLAB, Stata, SQL, Statistics, Eco...  \n",
      "1  Python, R, MATLAB, Stata, SQL, Statistics, Eco...  \n",
      "2  Python, R, MATLAB, Stata, SQL, Statistics, Eco...  \n",
      "3  Python, R, MATLAB, Stata, SQL, Statistics, Eco...  \n",
      "4  Python, TensorFlow, PyTorch, Scikit-learn, MLf...  \n"
     ]
    }
   ],
   "source": [
    "# RENAMING VARIABLES\n",
    "\n",
    "# Mapping dictionaries\n",
    "experience_map = {\n",
    "    'EN': 'Entry Level',\n",
    "    'MI': 'Mid Level',\n",
    "    'SE': 'Senior Level',\n",
    "    'EX': 'Executive'\n",
    "}\n",
    "\n",
    "employment_map = {\n",
    "    'FT': 'Full-time',\n",
    "    'PT': 'Part-time',\n",
    "    'CT': 'Contract',\n",
    "    'FL': 'Freelance'\n",
    "}\n",
    "\n",
    "remote_map = {\n",
    "    0: 'On-site',\n",
    "    50: 'Hybrid',\n",
    "    100: 'Remote'\n",
    "}\n",
    "\n",
    "company_size_map = {\n",
    "    'S': 'Small',\n",
    "    'M': 'Medium',\n",
    "    'L': 'Large'\n",
    "}\n",
    "\n",
    "# Apply mappings\n",
    "df['experience_level'] = df['experience_level'].map(experience_map)\n",
    "df['employment_type'] = df['employment_type'].map(employment_map)\n",
    "df['remote_ratio'] = df['remote_ratio'].map(remote_map)\n",
    "df['company_size'] = df['company_size'].map(company_size_map)\n",
    "\n",
    "# Optional: Rename 'remote_ratio' to 'work_location' for clarity\n",
    "df.rename(columns={'remote_ratio': 'work_location'}, inplace=True)\n",
    "\n",
    "# Display sample\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad7c3453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycountry-convert in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.7.2)\n",
      "Requirement already satisfied: pprintpp>=0.3.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pycountry-convert) (0.4.0)\n",
      "Requirement already satisfied: pycountry>=16.11.27.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pycountry-convert) (24.6.1)\n",
      "Requirement already satisfied: pytest>=3.4.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pycountry-convert) (8.4.1)\n",
      "Requirement already satisfied: pytest-mock>=1.6.3 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pycountry-convert) (3.14.1)\n",
      "Requirement already satisfied: pytest-cov>=2.5.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pycountry-convert) (6.2.1)\n",
      "Requirement already satisfied: repoze.lru>=0.7 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pycountry-convert) (0.7)\n",
      "Requirement already satisfied: wheel>=0.30.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pycountry-convert) (0.45.1)\n",
      "Requirement already satisfied: colorama>=0.4 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pytest>=3.4.0->pycountry-convert) (0.4.6)\n",
      "Requirement already satisfied: iniconfig>=1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pytest>=3.4.0->pycountry-convert) (2.1.0)\n",
      "Requirement already satisfied: packaging>=20 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pytest>=3.4.0->pycountry-convert) (25.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pytest>=3.4.0->pycountry-convert) (1.6.0)\n",
      "Requirement already satisfied: pygments>=2.7.2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pytest>=3.4.0->pycountry-convert) (2.19.2)\n",
      "Requirement already satisfied: coverage>=7.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from coverage[toml]>=7.5->pytest-cov>=2.5.1->pycountry-convert) (7.10.1)\n",
      "      company_location      continent\n",
      "0                   US  North America\n",
      "1                   US  North America\n",
      "2                   US  North America\n",
      "3                   US  North America\n",
      "4                   US  North America\n",
      "...                ...            ...\n",
      "93592               US  North America\n",
      "93593               US  North America\n",
      "93594               US  North America\n",
      "93595               US  North America\n",
      "93596               IN           Asia\n",
      "\n",
      "[93597 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['North America', 'Europe', 'Asia', 'South America', 'Oceania',\n",
       "       'Africa'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONTINENT\n",
    "\n",
    "!pip install pycountry-convert\n",
    "import pandas as pd\n",
    "import pycountry_convert as pc\n",
    "\n",
    "# Function to map ISO country code to continent\n",
    "def get_continent(iso_code):\n",
    "    try:\n",
    "        country_alpha2 = iso_code.upper()\n",
    "        country_continent_code = pc.country_alpha2_to_continent_code(country_alpha2)\n",
    "        continent_name = pc.convert_continent_code_to_continent_name(country_continent_code)\n",
    "        return continent_name\n",
    "    except:\n",
    "        return 'Unknown'\n",
    "\n",
    "# Apply the function to the 'company_location' column\n",
    "df['continent'] = df['company_location'].apply(get_continent)\n",
    "\n",
    "# Save or display result\n",
    "print(df[['company_location', 'continent']])\n",
    "\n",
    "df['continent'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e7bdceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   salary salary_currency  salary_in_usd_static\n",
      "0  208000             USD              208000.0\n",
      "1  147000             USD              147000.0\n",
      "2  173000             USD              173000.0\n",
      "3  117000             USD              117000.0\n",
      "4  100000             USD              100000.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([208000., 147000., 173000., ..., 138350., 423000., 412000.],\n",
       "      shape=(9088,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CURRENCY CONVERSION\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Example currency-to-USD rates (update these if needed)\n",
    "currency_to_usd = {\n",
    "    'USD': 1,\n",
    "    'EUR': 1.09,\n",
    "    'GBP': 1.28,\n",
    "    'TWD': 0.031,\n",
    "    'BRL': 0.19,\n",
    "    'CAD': 0.73,\n",
    "    'HUF': 0.0028,\n",
    "    'PLN': 0.25,\n",
    "    'JPY': 0.0063,\n",
    "    'PHP': 0.017,\n",
    "    'CHF': 1.13,\n",
    "    'INR': 0.012,\n",
    "    'NOK': 0.094,\n",
    "    'SGD': 0.74,\n",
    "    'AUD': 0.67,\n",
    "    'DKK': 0.15,\n",
    "    'CZK': 0.043,\n",
    "    'MXN': 0.055,\n",
    "    'ILS': 0.27,\n",
    "    'TRY': 0.031,\n",
    "    'ZAR': 0.056,\n",
    "    'SEK': 0.093,\n",
    "    'NZD': 0.61,\n",
    "    'HKD': 0.13,\n",
    "    'THB': 0.028,\n",
    "    'CLP': 0.0011\n",
    "}\n",
    "\n",
    "\n",
    "# Apply static conversion\n",
    "df['salary_in_usd_static'] = df.apply(\n",
    "    lambda row: round(row['salary'] * currency_to_usd.get(row['salary_currency'], 0), 2),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# View result\n",
    "print(df[['salary', 'salary_currency', 'salary_in_usd_static']].head())\n",
    "\n",
    "df['salary_in_usd_static'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114d68bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(93597)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DATA POINTS\n",
    "df['salary_in_usd_static'].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf2550c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "\n",
      "   ---------------------------------------- 0/2 [et-xmlfile]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   ---------------------------------------- 2/2 [openpyxl]\n",
      "\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n",
      "Data saved successfully.\n"
     ]
    }
   ],
   "source": [
    "#SAVE DATA\n",
    "\n",
    "!pip install openpyxl\n",
    "\n",
    "\n",
    "df.to_excel(r\"C:\\Users\\DELL\\Downloads\\archive\\DataScience_salaries_2025_processed.xlsx\", index=False)\n",
    "print(\"Data saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d87056e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbformat in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (5.10.4)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nbformat) (2.21.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nbformat) (4.25.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\dell\\appdata\\roaming\\python\\python313\\site-packages (from nbformat) (5.8.1)\n",
      "Requirement already satisfied: traitlets>=5.1 in c:\\users\\dell\\appdata\\roaming\\python\\python313\\site-packages (from nbformat) (5.14.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=2.6->nbformat) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=2.6->nbformat) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=2.6->nbformat) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=2.6->nbformat) (0.26.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\dell\\appdata\\roaming\\python\\python313\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (4.3.8)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\dell\\appdata\\roaming\\python\\python313\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (311)\n",
      "Requirement already satisfied: plotly in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (6.2.0)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from plotly) (1.48.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from plotly) (25.0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        </script>\n",
       "        <script type=\"module\">import \"https://cdn.plot.ly/plotly-3.0.1.min\"</script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'choropleth.html'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#HEATMAP\n",
    "\n",
    "!pip install nbformat\n",
    "!pip install plotly\n",
    "import plotly.express as px\n",
    "import plotly.offline as pyo\n",
    "import pycountry\n",
    "\n",
    "# Convert 2-letter country code to 3-letter using pycountry\n",
    "def convert_to_iso3(code):\n",
    "    try:\n",
    "        return pycountry.countries.get(alpha_2=code).alpha_3\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df['country_iso3'] = df['company_location'].apply(convert_to_iso3)\n",
    "# Make sure it contains 'country_code' (ISO Alpha-3) and 'salary_in_usd'\n",
    "\n",
    "avg_salary_by_country = df.groupby('country_iso3')[\"salary_in_usd_static\"].mean().reset_index()\n",
    "avg_salary_by_country.columns = ['country_iso3', 'avg_salary_usd']\n",
    "\n",
    "fig = px.choropleth(\n",
    "    avg_salary_by_country,\n",
    "    locations='country_iso3',\n",
    "    color=\"avg_salary_usd\",\n",
    "    color_continuous_scale=\"Viridis\",\n",
    "    title=\"🌍 Average Salary (USD) by Country\"\n",
    ")\n",
    "\n",
    "# Use plotly offline to render in notebook\n",
    "pyo.init_notebook_mode(connected=True)\n",
    "pyo.plot(fig, filename=\"choropleth.html\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
